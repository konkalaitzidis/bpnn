{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8641416e-7f1a-49a6-99f1-9194aa7e667d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabf220e-e0cb-42bd-9543-1d23beba6e56",
   "metadata": {},
   "source": [
    "NOTE: This is the main file of the BPNN pipeline. All dependencies are within a conda environment to ensure reproducibility. To install all dependencies: pip install -r requirements.txt### Step 1: Make sure Tensorflow finds the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b200f-3e53-4370-aea7-273c69da06f6",
   "metadata": {},
   "source": [
    "### Step 1: Make sure Tensorflow finds the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe2fb28-88bc-489b-bb16-755c927255a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc5e9a4-74d0-42b9-af23-2e07ddde6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Lets see if it works\n",
    "tf.ones(1) + tf.ones(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f8a7f-c5f8-47c5-835d-db40f8f2a502",
   "metadata": {},
   "source": [
    "### Step 2: Import all libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9628b322-4fc7-4193-893d-5de0b8347f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for working with arrays and matrices\n",
    "import pandas as pd # for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import seaborn as sns # for data visualization\n",
    "\n",
    "import os # OS module provides various operating system-related functions to the code\n",
    "# import csv # CSV module is used for working with CSV (Comma Separated Values) files in Python.\n",
    "import pickle\n",
    "\n",
    "# # used for splitting data into training and testing sets in Python.\n",
    "# from sklearn.model_selection import train_test_split \n",
    "\n",
    "# # for generating a confusion matrix\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import f1_score\n",
    "# from keras.models import load_model\n",
    "\n",
    "\n",
    "# # Classes and functions from the Keras library which is used for building and training deep learning models in Python.\n",
    "# from keras.models import model_from_json\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "# from save_model_info import save_training_info\n",
    "\n",
    "\n",
    "# # These import the Adam optimizer class and various other classes from the TensorFlow Keras library \n",
    "# # which is a high-level neural networks API used for building and training deep learning models in Python.\n",
    "# from tensorflow.keras.optimizers.legacy import Adam\n",
    "# from tensorflow.keras import datasets, layers, models\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# from plots import plot_confusion_matrix, plot_accuracy, plot_loss, plot_accuracy_k_fold, plot_loss_k_fold, plot_average_accuracy_k_fold, plot_average_loss_k_fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec34b34-3635-4c3a-8151-fe9161e10f4f",
   "metadata": {},
   "source": [
    "### Step 2: Loading variables from the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf31c4-2a39-4384-b0f7-96a2a8ccba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_just_executed = True # True if you are plotting results from a model you just ran\n",
    "\n",
    "if model_just_executed == True:\n",
    "    \n",
    "    %store -r experiment_ID\n",
    "    print(\"Printing results from experiment \"+experiment_ID)\n",
    "    %store -r save_dir\n",
    "    print(\"from path: \"+save_dir)\n",
    "\n",
    "    print(\"Restoring variables from model execution...\\nDone\")\n",
    "    %store -r f1_score_val_list\n",
    "    %store -r f1_score_mean\n",
    "    %store -r num_folds\n",
    "    %store -r conf_matrices\n",
    "    %store -r epochs\n",
    "    %store -r output_dir\n",
    "    %store -r data_file\n",
    "    %store -r no_of_labels\n",
    "    %store -r train_labels_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b1d77-8c1b-4760-8bea-32d8ab2c06c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_just_executed == True:\n",
    "    \n",
    "    print(\"Plotting Confusion Matrix of \"+experiment_ID)\n",
    "    #plot the mean confusion matrix\n",
    "    mean_cm = np.mean(conf_matrices, axis=0)\n",
    "    # train_labels_names = ['Grooming', 'Frozen', 'Not Moving', 'Moving', 'Right Turn', 'Left Turn']\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(mean_cm, annot=True, cmap='Blues', fmt='g')\n",
    "    plt.title('Mean Confusion Matrix (5-Fold CV)', fontsize=8)\n",
    "    plt.xlabel('Predicted Labels', fontsize=8)\n",
    "    plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, ha='center', fontsize=7)\n",
    "    plt.ylabel('True Labels', fontsize=8)\n",
    "    plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=7)\n",
    "    plt.savefig(save_dir+'/cm/'+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "    ####-----####\n",
    "    \n",
    "    print(\"Loading pickels to make more plots...\\nDone\")\n",
    "    dir_path = output_dir+'/pickles/'\n",
    "\n",
    "    # read results from model execution in order to plot them\n",
    "    with open(os.path.join(dir_path,'average_score_list.pkl'), 'rb') as f:\n",
    "        average_score_list = pickle.load(f)\n",
    "        average_score_list = pd.DataFrame(average_score_list)\n",
    "    with open(os.path.join(dir_path,'conf_matrices.pkl'), 'rb') as f:\n",
    "        conf_matrices = pickle.load(f)\n",
    "        # conf_matrices = pd.DataFrame(conf_matrices)\n",
    "    with open(os.path.join(dir_path,'train_acc_all.pkl'), 'rb') as f:\n",
    "        train_acc_all = pickle.load(f)\n",
    "        train_acc_all = pd.DataFrame(train_acc_all)\n",
    "    with open(os.path.join(dir_path,'train_loss_all.pkl'), 'rb') as f:\n",
    "        train_loss_all = pickle.load(f)\n",
    "        train_loss_all = pd.DataFrame(train_loss_all)\n",
    "    with open(os.path.join(dir_path,'val_acc_all.pkl'), 'rb') as f:\n",
    "        val_acc_all = pickle.load(f)\n",
    "        val_acc_all = pd.DataFrame(val_acc_all)\n",
    "    with open(os.path.join(dir_path,'val_loss_all.pkl'), 'rb') as f:\n",
    "        val_loss_all = pickle.load(f)\n",
    "        val_loss_all = pd.DataFrame(val_loss_all)\n",
    "\n",
    "    print(\"Setting paths to save results...\\nDone\")\n",
    "    \n",
    "    acc_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/\"+str(output_dir)+\"/accuracy\"\n",
    "    loss_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/\"+str(output_dir)+\"/loss\"\n",
    "    \n",
    "    ####-----####\n",
    "    \n",
    "    print(\"Plotting Accuracy and Loss for \"+experiment_ID)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_palette('husl')\n",
    "\n",
    "    min_length = len(val_loss_all)\n",
    "\n",
    "    # Plot the averaged results - subplot 1\n",
    "    sns.lineplot(x=range(min_length), y=train_acc_all, label='Train Acc', linewidth=2.5, color='#880454', ax=axs[0])\n",
    "    sns.lineplot(x=range(min_length), y=train_loss_all, label='Val Acc', linewidth=2.5, color='#2596be', ax=axs[0])\n",
    "\n",
    "    axs[0].set_title('Training and Validation Accuracy (5-Fold CV)', fontsize=10)\n",
    "    axs[0].set_xlabel('Epoch', fontsize=10)\n",
    "    axs[0].set_ylabel('Accuracy', fontsize=10)\n",
    "    axs[0].legend(loc='upper left')\n",
    "\n",
    "    # Plot the averaged results - subplot 2\n",
    "    sns.lineplot(x=range(min_length), y=train_loss_avg, label='Train Loss', linewidth=2.5, color='#880454', ax=axs[1])\n",
    "    sns.lineplot(x=range(min_length), y=val_loss_avg, label='Val Loss', linewidth=2.5, color='#2596be', ax=axs[1])\n",
    "\n",
    "    axs[1].set_title('Training and Validation Loss (5-Fold CV)', fontsize=10)\n",
    "    axs[1].set_xlabel('Epoch', fontsize=10)\n",
    "    axs[1].set_ylabel('Loss', fontsize=10)\n",
    "    axs[1].legend(loc='lower left')\n",
    "        \n",
    "\n",
    "    plt.savefig(save_dir+\"/accuracy/\"+\"training-validation-accuracy_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8ec37-0740-4e5b-9263-bc673df048b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "min_length = len(val_loss_all)\n",
    "\n",
    "# Plot the averaged results - subplot 1\n",
    "for acc, loss in zip(train_acc_all, train_loss_all):\n",
    "    sns.lineplot(x=range(min_length), y=acc, label='Train Acc', linewidth=2.5, color='#880454', ax=axs[0])\n",
    "    sns.lineplot(x=range(min_length), y=loss, label='Val Acc', linewidth=2.5, color='#2596be', ax=axs[0])\n",
    "    \n",
    "#     sns.lineplot(x=range(min_length), y=train_loss_avg, label='Train Loss', linewidth=2.5, color='#880454', ax=axs[1])\n",
    "#     sns.lineplot(x=range(min_length), y=val_loss_avg, label='Val Loss', linewidth=2.5, color='#2596be', ax=axs[1])\n",
    "\n",
    "#     axs[1].set_title('Training and Validation Loss (5-Fold CV)', fontsize=10)\n",
    "#     axs[1].set_xlabel('Epoch', fontsize=10)\n",
    "#     axs[1].set_ylabel('Loss', fontsize=10)\n",
    "#     axs[1].legend(loc='lower left')\n",
    "\n",
    "axs[0].set_title('Training and Validation Accuracy (5-Fold CV)', fontsize=10)\n",
    "axs[0].set_xlabel('Epoch', fontsize=10)\n",
    "axs[0].set_ylabel('Accuracy', fontsize=10)\n",
    "axs[0].legend(loc='upper left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0549606-abe1-41c9-a1eb-bfe7c181fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377841e-3595-47d7-b5cf-153ff8b948cb",
   "metadata": {},
   "source": [
    "### Load current or previous data for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a3b2f-7c86-488a-9304-440557a80616",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = num_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a70016-f43a-48b9-b5db-d37507058830",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_existing_data = True\n",
    "\n",
    "if load_existing_data == True:\n",
    "    \n",
    "    # fetch resutls\n",
    "    model_results_dir = save_dir+\"/pickles\"\n",
    "    \n",
    "    \n",
    "#     with open(os.path.join(model_results_dir,'val_loss_avg.pkl'), 'rb') as f:\n",
    "#         val_loss_avg = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_results_dir,'val_acc_avg.pkl'), 'rb') as f:\n",
    "#         val_acc_avg = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_results_dir,'train_loss_avg.pkl'), 'rb') as f:\n",
    "#         train_loss_avg = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_results_dir,'train_acc_avg.pkl'), 'rb') as f:\n",
    "#         train_acc_avg = pickle.load(f)\n",
    "        \n",
    "#     with open(os.path.join(model_results_dir,'train_acc_avg.pkl'), 'rb') as f:\n",
    "#         train_acc_avg = pickle.load(f)\n",
    "    \n",
    "#     with open(os.path.join(model_results_dir,'conf_matrices.pkl'), 'rb') as f:\n",
    "#         conf_matrices = pickle.load(f)\n",
    "            \n",
    "#     with open(os.path.join(model_results_dir,'train_labels_names.pkl'), 'rb') as f:\n",
    "#         train_labels_names = pickle.load(f)\n",
    "        \n",
    "    \n",
    "    with open(os.path.join(model_results_dir,'val_loss_all.pkl'), 'rb') as f:\n",
    "        val_loss_avg = pickle.load(f)\n",
    "        val_loss_avg = pd.DataFrame(val_loss_avg)\n",
    "\n",
    "\n",
    "    with open(os.path.join(model_results_dir,'val_acc_all.pkl'), 'rb') as f:\n",
    "        val_acc_avg = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(model_results_dir,'train_loss_all.pkl'), 'rb') as f:\n",
    "        train_loss_avg = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(model_results_dir,'train_acc_all.pkl'), 'rb') as f:\n",
    "        train_acc_avg = pickle.load(f)\n",
    "        \n",
    "    # with open(os.path.join(model_results_dir,'train_acc_avg.pkl'), 'rb') as f:\n",
    "    #     train_acc_avg = pickle.load(f)\n",
    "    \n",
    "    with open(os.path.join(model_results_dir,'conf_matrices.pkl'), 'rb') as f:\n",
    "        conf_matrices = pickle.load(f)\n",
    "            \n",
    "    # with open(os.path.join(model_results_dir,'train_labels_names.pkl'), 'rb') as f:\n",
    "    #     train_labels_names = pickle.load(f)\n",
    "    \n",
    "#     with open(os.path.join(model_acc_dir,'cm_avg.pkl'), 'rb') as f:\n",
    "#         cm_avg = pickle.load(f)\n",
    "#     # with open(os.path.join(model_acc_dir,'accuracies.pkl'), 'rb') as f:\n",
    "#     #     cm_avg = accuracies.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_acc_dir,'losses.pkl'), 'rb') as f:\n",
    "#         losses = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_acc_dir,'shuffled_accuracies.pkl'), 'rb') as f:\n",
    "#         shuffled_accuracies = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_acc_dir,'shuffled_cm_avg.pkl'), 'rb') as f:\n",
    "#         shuffled_cm_avg = pickle.load(f)\n",
    "        \n",
    "#     with open(os.path.join(model_acc_dir,'shuffled_losses.pkl'), 'rb') as f:\n",
    "#         shuffled_losses = pickle.load(f)\n",
    "        \n",
    "#     with open(os.path.join(model_acc_dir,'train_labels_names.pkl'), 'rb') as f:\n",
    "#         train_labels_names = pickle.load(f)\n",
    "    \n",
    "        \n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_palette('husl')\n",
    "\n",
    "    min_length = len(val_loss_all)\n",
    "\n",
    "    # Plot the averaged results - subplot 1\n",
    "    sns.lineplot(x=range(min_length), y=train_acc_avg, label='Train Acc', linewidth=2.5, color='#880454', ax=axs[0])\n",
    "    sns.lineplot(x=range(min_length), y=train_loss_avg, label='Val Acc', linewidth=2.5, color='#2596be', ax=axs[0])\n",
    "\n",
    "    axs[0].set_title('Training and Validation Accuracy (5-Fold CV)', fontsize=10)\n",
    "    axs[0].set_xlabel('Epoch', fontsize=10)\n",
    "    axs[0].set_ylabel('Accuracy', fontsize=10)\n",
    "    axs[0].legend(loc='upper left')\n",
    "\n",
    "    # Plot the averaged results - subplot 2\n",
    "    sns.lineplot(x=range(min_length), y=train_loss_avg, label='Train Loss', linewidth=2.5, color='#880454', ax=axs[1])\n",
    "    sns.lineplot(x=range(min_length), y=val_loss_avg, label='Val Loss', linewidth=2.5, color='#2596be', ax=axs[1])\n",
    "\n",
    "    axs[1].set_title('Training and Validation Loss (5-Fold CV)', fontsize=10)\n",
    "    axs[1].set_xlabel('Epoch', fontsize=10)\n",
    "    axs[1].set_ylabel('Loss', fontsize=10)\n",
    "    axs[1].legend(loc='lower left')\n",
    "    \n",
    "    \n",
    "    experiment_ID = \"4_output\"\n",
    "    \n",
    "\n",
    "    plt.savefig(model_results_dir+\"/\"+\"training-validation-accuracy_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #plot the mean confusion matrix\n",
    "    # mean_cm = np.mean(conf_matrices, axis=0)\n",
    "    # train_labels_names = ['moving', 'rightTurn', 'immobile', 'grooming', 'still', 'leftTurn']\n",
    "    # plt.figure(figsize=(7, 5))\n",
    "    # sns.heatmap(mean_cm, annot=True, cmap='Blues', fmt='g')\n",
    "    # plt.title('Mean Confusion Matrix (5-Fold CV)', fontsize=12)\n",
    "    # plt.xlabel('Predicted Labels', fontsize=12)\n",
    "    # plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, ha='center', fontsize=7)\n",
    "    # plt.ylabel('True Labels', fontsize=12)\n",
    "    # plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=7)\n",
    "    # plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=600)\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    mean_cm = np.mean(conf_matrices, axis=0)\n",
    "    train_labels_names = ['grooming', 'frozen', 'not moving', 'moving', 'right turn', 'left turn']    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(mean_cm, annot=False, cmap='Blues', fmt='g')\n",
    "    plt.title('Mean Confusion Matrix - (5-Fold CV)', fontsize=12)\n",
    "    plt.xlabel('Predicted Labels', fontsize=10)\n",
    "    plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    plt.ylabel('True Labels', fontsize=10)\n",
    "    plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b9918-cacc-4c33-ac40-470472ba7b59",
   "metadata": {},
   "source": [
    "## Average F1-Score for each Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a82c47-1fb6-4818-865a-1e3201d3568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar plot\n",
    "# x = np.arange(1, 6)\n",
    "# width = 0.3\n",
    "\n",
    "f1_list = []\n",
    "for conf_matrix in conf_matrices:\n",
    "    precision = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "    recall = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    f1_list.append(np.mean(f1))\n",
    "\n",
    "labels = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "\n",
    "# Choose a color palette from seaborn's built-in palettes\n",
    "color_palette = 'Set2'\n",
    "\n",
    "ax = sns.barplot(x=labels, y=f1_list, color = \"#2596be\")\n",
    "plt.xlabel('Fold', fontsize=12)\n",
    "plt.ylabel('F1 Score', fontsize=12)\n",
    "plt.title('Average F1-Score for each Fold', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add value annotations inside each bar\n",
    "for i, v in enumerate(f1_list):\n",
    "    ax.text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "# ax.bar(x + width, f1_list, width, label='F1-Score', color='navy')\n",
    "\n",
    "# ax.set_title('Average F1-Score per Fold', fontsize=14, fontweight='bold')\n",
    "# ax.set_xlabel('Fold', fontsize=12)\n",
    "# ax.set_ylabel('Score', fontsize=12)\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(np.arange(1, 6), rotation=0, fontsize=12)\n",
    "# ax.legend()\n",
    "\n",
    "# ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366fb2b4-8d67-48d1-8901-ab11da895571",
   "metadata": {},
   "source": [
    "## Mean CM and Average Precision, Recall, and F1-Score per Behaviour Label for the Mean CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94b501-3d1b-415d-b509-8a28dc830dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score per class label\n",
    "precision = np.diag(mean_cm) / np.sum(mean_cm, axis=0)\n",
    "recall = np.diag(mean_cm) / np.sum(mean_cm, axis=1)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Create labels with F1-score included\n",
    "f1_labels = [f\"{label}\\n{f1_score:.2f}\" for label, f1_score in zip(train_labels_names, f1)]\n",
    "\n",
    "# Plot mean confusion matrix with F1-score labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.heatmap(mean_cm, annot=False, cmap='Blues', fmt='g', annot_kws={\"fontsize\": 10}, xticklabels=f1_labels, yticklabels=train_labels_names)\n",
    "\n",
    "plt.title('Mean Confusion Matrix - (5-Fold CV)', fontsize=12)\n",
    "plt.xlabel('Predicted Labels', fontsize=10)\n",
    "plt.ylabel('True Labels', fontsize=10)\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "plt.savefig(\"mean_CM.svg\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # Create bar plot\n",
    "# x = np.arange(len(train_labels_names))\n",
    "# width = 0.2\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# bars_precision = ax.bar(x, precision, width, label='Precision', color='blue')\n",
    "# bars_recall = ax.bar(x + width, recall, width, label='Recall', color='lightblue')\n",
    "# bars_f1 = ax.bar(x + (2 * width), f1, width, label='F1-Score', color='darkblue')\n",
    "\n",
    "# ax.set_title('Precision, Recall, and F1-Score per Class Label', fontsize=12)\n",
    "# ax.set_xlabel('Class Label', fontsize=10)\n",
    "# ax.set_ylabel('Score', fontsize=10)\n",
    "# ax.set_xticks(x + width)\n",
    "# ax.set_xticklabels(train_labels_names, rotation=45)\n",
    "# ax.legend()\n",
    "\n",
    "\n",
    "# plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "# Calculate precision, recall, and F1-score per class label\n",
    "# precision = np.diag(mean_cm) / np.sum(mean_cm, axis=0)\n",
    "# recall = np.diag(mean_cm) / np.sum(mean_cm, axis=1)\n",
    "# f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "\n",
    "# Create bar plot\n",
    "x = np.arange(len(train_labels_names))\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.bar(x - width, precision, width, label='Precision', color='cornflowerblue')\n",
    "ax.bar(x, recall, width, label='Recall', color='navy')\n",
    "ax.bar(x + width, f1, width, label='F1-Score', color='darkmagenta')\n",
    "\n",
    "ax.set_title('Precision, Recall, and F1-Score per Behaviour Label', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Class Label', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(train_labels_names, rotation=0, fontsize=12)\n",
    "ax.legend()\n",
    "\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print precision, recall, and F1-score per class label\n",
    "for label, prec, rec, f1_score in zip(train_labels_names, precision, recall, f1):\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"Precision: {prec:.2f}\")\n",
    "    print(f\"Recall: {rec:.2f}\")\n",
    "    print(f\"F1-Score: {f1_score:.2f}\")\n",
    "    print()\n",
    "\n",
    "# Save results to CSV\n",
    "model_results_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/Experiment_4-BPNNt_output/results\"\n",
    "csv_path = model_results_dir + \"/results.csv\"\n",
    "\n",
    "with open(csv_path, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Label\", \"Precision\", \"Recall\", \"F1-Score\"])  # Write header\n",
    "    for label, prec, rec, f1_score in zip(train_labels_names, precision, recall, f1):\n",
    "        writer.writerow([label, f\"{prec:.2f}\", f\"{rec:.2f}\", f\"{f1_score:.2f}\"])\n",
    "\n",
    "print(f\"Results saved to: {csv_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670855cc-54b4-4e3c-9848-1a34391b3416",
   "metadata": {},
   "source": [
    "## F1-Score per Label for each Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60265f47-6b52-470f-a735-1892128c9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_list = []\n",
    "j = 1\n",
    "for conf_matrix in conf_matrices:\n",
    "    precision = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "    recall = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    f1 = np.transpose(f1)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    for i, label in enumerate(train_labels_names):\n",
    "        ax.bar(train_labels_names, f1, width=0.5, label=label, color=\"navy\")\n",
    "        for x, y in enumerate(f1):\n",
    "            ax.text(x, y + 0.01, f\"{y:.2f}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    ax.set_title('F1-Score per Label for Fold ' + str(j), fontsize=12)\n",
    "    j = j + 1\n",
    "    ax.set_xlabel('Fold', fontsize=10)\n",
    "    ax.set_ylabel('F1 Score', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"score_bar_plot_fold_{j}.svg\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08341c1-75ed-459d-9291-b7af9ef93696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For plotting the barplot\n",
    "\n",
    "# # Create bar plot\n",
    "# x = np.arange(len(train_labels_names))\n",
    "# width = 0.3\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# ax.bar(x - width, precision, width, label='Precision', color='cornflowerblue')\n",
    "# ax.bar(x, recall, width, label='Recall', color='navy')\n",
    "# ax.bar(x + width, f1, width, label='F1-Score', color='darkmagenta')\n",
    "\n",
    "# ax.set_title('Precision, Recall, and F1-Score per Behaviour Label', fontsize=14, fontweight='bold')\n",
    "# ax.set_xlabel('Class Label', fontsize=12)\n",
    "# ax.set_ylabel('Score', fontsize=12)\n",
    "# ax.set_xticks(x)\n",
    "# ax.set_xticklabels(train_labels_names, rotation=0, fontsize=12)\n",
    "# ax.legend()\n",
    "\n",
    "# ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9119b02-b49a-4c86-8177-20e187b3d5bf",
   "metadata": {},
   "source": [
    "## Load Shuffled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974227b-9d81-4bd2-a3dd-763f1baa5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_existing_shuffled_data = True\n",
    "\n",
    "if load_existing_shuffled_data == True:\n",
    "    \n",
    "    # fetch resutls\n",
    "    model_shuffled_results_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/Experiment_4 - BPNNt - chance_output/results\"\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(model_shuffled_results_dir,'val_loss_avg.pkl'), 'rb') as f:\n",
    "        val_loss_avg_shuffled = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(model_shuffled_results_dir,'val_acc_avg.pkl'), 'rb') as f:\n",
    "        val_acc_avg_shuffled = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(model_shuffled_results_dir,'train_loss_avg.pkl'), 'rb') as f:\n",
    "        train_loss_avg_shuffled = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(model_shuffled_results_dir,'train_acc_avg.pkl'), 'rb') as f:\n",
    "        train_acc_avg_shuffled = pickle.load(f)\n",
    "        \n",
    "    with open(os.path.join(model_shuffled_results_dir,'train_acc_avg.pkl'), 'rb') as f:\n",
    "        train_acc_avg_shuffled = pickle.load(f)\n",
    "    \n",
    "    with open(os.path.join(model_shuffled_results_dir,'conf_matrices.pkl'), 'rb') as f:\n",
    "        conf_matrices_shuffled = pickle.load(f)\n",
    "            \n",
    "    with open(os.path.join(model_shuffled_results_dir,'train_labels_names.pkl'), 'rb') as f:\n",
    "        train_labels_names = pickle.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "#     with open(os.path.join(model_acc_dir,'cm_avg.pkl'), 'rb') as f:\n",
    "#         cm_avg = pickle.load(f)\n",
    "#     # with open(os.path.join(model_acc_dir,'accuracies.pkl'), 'rb') as f:\n",
    "#     #     cm_avg = accuracies.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_acc_dir,'losses.pkl'), 'rb') as f:\n",
    "#         losses = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_acc_dir,'shuffled_accuracies.pkl'), 'rb') as f:\n",
    "#         shuffled_accuracies = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_acc_dir,'shuffled_cm_avg.pkl'), 'rb') as f:\n",
    "#         shuffled_cm_avg = pickle.load(f)\n",
    "        \n",
    "#     with open(os.path.join(model_acc_dir,'shuffled_losses.pkl'), 'rb') as f:\n",
    "#         shuffled_losses = pickle.load(f)\n",
    "        \n",
    "#     with open(os.path.join(model_acc_dir,'train_labels_names.pkl'), 'rb') as f:\n",
    "#         train_labels_names = pickle.load(f)\n",
    "    \n",
    "        \n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_palette('husl')\n",
    "\n",
    "    min_length = len(val_loss_avg_shuffled)\n",
    "\n",
    "    # Plot the averaged results - subplot 1\n",
    "    sns.lineplot(x=range(min_length), y=train_acc_avg_shuffled, label='Train Acc', linewidth=2.5, color='#880454', ax=axs[0])\n",
    "    sns.lineplot(x=range(min_length), y=val_acc_avg_shuffled, label='Val Acc', linewidth=2.5, color='#2596be', ax=axs[0])\n",
    "\n",
    "    axs[0].set_title('Training and Validation Accuracy (5-Fold CV)', fontsize=10)\n",
    "    axs[0].set_xlabel('Epoch', fontsize=10)\n",
    "    axs[0].set_ylabel('Accuracy', fontsize=10)\n",
    "    axs[0].legend(loc='upper left')\n",
    "\n",
    "    # Plot the averaged results - subplot 2\n",
    "    sns.lineplot(x=range(min_length), y=train_loss_avg_shuffled, label='Train Loss', linewidth=2.5, color='#880454', ax=axs[1])\n",
    "    sns.lineplot(x=range(min_length), y=val_loss_avg_shuffled, label='Val Loss', linewidth=2.5, color='#2596be', ax=axs[1])\n",
    "\n",
    "    axs[1].set_title('Training and Validation Loss (5-Fold CV)', fontsize=10)\n",
    "    axs[1].set_xlabel('Epoch', fontsize=10)\n",
    "    axs[1].set_ylabel('Loss', fontsize=10)\n",
    "    axs[1].legend(loc='lower left')\n",
    "    \n",
    "    \n",
    "    experiment_ID = \"4_shuffled_output\"\n",
    "    \n",
    "\n",
    "    plt.savefig(model_results_dir+\"/\"+\"training-validation-accuracy_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #plot the mean confusion matrix\n",
    "    # mean_cm = np.mean(conf_matrices, axis=0)\n",
    "    # train_labels_names = ['moving', 'rightTurn', 'immobile', 'grooming', 'still', 'leftTurn']\n",
    "    # plt.figure(figsize=(7, 5))\n",
    "    # sns.heatmap(mean_cm, annot=True, cmap='Blues', fmt='g')\n",
    "    # plt.title('Mean Confusion Matrix (5-Fold CV)', fontsize=12)\n",
    "    # plt.xlabel('Predicted Labels', fontsize=12)\n",
    "    # plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, ha='center', fontsize=7)\n",
    "    # plt.ylabel('True Labels', fontsize=12)\n",
    "    # plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=7)\n",
    "    # plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=600)\n",
    "    # plt.show()\n",
    "    \n",
    "    \n",
    "    mean_cm_shuffled = np.mean(conf_matrices_shuffled, axis=0)\n",
    "    train_labels_names = ['grooming', 'frozen', 'not moving', 'moving', 'right turn', 'left turn']    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(mean_cm_shuffled, annot=False, cmap='Blues', fmt='g')\n",
    "    plt.title('Mean Confusion Matrix - (5-Fold CV)', fontsize=12)\n",
    "    plt.xlabel('Predicted Labels', fontsize=10)\n",
    "    plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    plt.ylabel('True Labels', fontsize=10)\n",
    "    plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f70664-1072-4115-997a-bf709f278366",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cm_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6731e39-cc74-4c81-ade1-b8f32da6339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # conf matrices\n",
    "# f1_list = []\n",
    "# for conf_matrix in conf_matrices_shuffled:\n",
    "#     precision = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "#     recall = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     f1_list.append(np.mean(f1))\n",
    "\n",
    "# labels = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "\n",
    "# # Choose a color palette from seaborn's built-in palettes\n",
    "# color_palette = 'Set2'\n",
    "\n",
    "# ax = sns.barplot(x=labels, y=f1_list, color = \"navy\")\n",
    "# plt.xlabel('Fold', fontsize=12)\n",
    "# plt.ylabel('F1 Score', fontsize=12)\n",
    "# plt.title('Average F1-Score for each Fold', fontsize=14, fontweight='bold')\n",
    "\n",
    "# # Add value annotations inside each bar\n",
    "# for i, v in enumerate(f1_list):\n",
    "#     ax.text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9202ed95-bd1b-46a4-9d2a-7295b65abe03",
   "metadata": {},
   "source": [
    "## Load BPSVMt one video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407de79-eb78-4486-b293-6b59d0cd0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_existing_shuffled_data = True\n",
    "\n",
    "if load_existing_shuffled_data == True:\n",
    "    \n",
    "    # fetch resutls\n",
    "    BPSVMt_results_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/Exp_4.3_BPSVMt_one_video_output/results\"\n",
    "    \n",
    "    \n",
    "#     with open(os.path.join(model_shuffled_results_dir,'val_loss_avg.pkl'), 'rb') as f:\n",
    "#         val_loss_avg_shuffled = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_shuffled_results_dir,'val_acc_avg.pkl'), 'rb') as f:\n",
    "#         val_acc_avg_shuffled = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_shuffled_results_dir,'train_loss_avg.pkl'), 'rb') as f:\n",
    "#         train_loss_avg_shuffled = pickle.load(f)\n",
    "\n",
    "#     with open(os.path.join(model_shuffled_results_dir,'train_acc_avg.pkl'), 'rb') as f:\n",
    "#         train_acc_avg_shuffled = pickle.load(f)\n",
    "        \n",
    "#     with open(os.path.join(model_shuffled_results_dir,'train_acc_avg.pkl'), 'rb') as f:\n",
    "#         train_acc_avg_shuffled = pickle.load(f)\n",
    "    \n",
    "#     with open(os.path.join(model_shuffled_results_dir,'conf_matrices.pkl'), 'rb') as f:\n",
    "#         conf_matrices_shuffled = pickle.load(f)\n",
    "            \n",
    "#     with open(os.path.join(model_shuffled_results_dir,'train_labels_names.pkl'), 'rb') as f:\n",
    "#         train_labels_names = pickle.load(f)\n",
    "    \n",
    "\n",
    "\n",
    "    with open(os.path.join(BPSVMt_results_dir,'cm_avg.pkl'), 'rb') as f:\n",
    "        cm_avg = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(BPSVMt_results_dir,'accuracies.pkl'), 'rb') as f:\n",
    "        accuracies = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(BPSVMt_results_dir,'losses.pkl'), 'rb') as f:\n",
    "        losses = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(BPSVMt_results_dir,'shuffled_accuracies.pkl'), 'rb') as f:\n",
    "        shuffled_accuracies = pickle.load(f)\n",
    "\n",
    "    with open(os.path.join(BPSVMt_results_dir,'shuffled_cm_avg.pkl'), 'rb') as f:\n",
    "        shuffled_cm_avg = pickle.load(f)\n",
    "        \n",
    "    with open(os.path.join(BPSVMt_results_dir,'shuffled_losses.pkl'), 'rb') as f:\n",
    "        shuffled_losses = pickle.load(f)\n",
    "        \n",
    "    # with open(os.path.join(model_acc_dir,'train_labels_names.pkl'), 'rb') as f:\n",
    "    #     train_labels_names = pickle.load(f)\n",
    "    \n",
    "        \n",
    "\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "#     sns.set_style('whitegrid')\n",
    "#     sns.set_palette('husl')\n",
    "\n",
    "#     min_length = len(val_loss_avg_shuffled)\n",
    "\n",
    "#     # Plot the averaged results - subplot 1\n",
    "#     sns.lineplot(x=range(min_length), y=train_acc_avg_shuffled, label='Train Acc', linewidth=2.5, color='#880454', ax=axs[0])\n",
    "#     sns.lineplot(x=range(min_length), y=val_acc_avg_shuffled, label='Val Acc', linewidth=2.5, color='#2596be', ax=axs[0])\n",
    "\n",
    "#     axs[0].set_title('Training and Validation Accuracy (5-Fold CV)', fontsize=10)\n",
    "#     axs[0].set_xlabel('Epoch', fontsize=10)\n",
    "#     axs[0].set_ylabel('Accuracy', fontsize=10)\n",
    "#     axs[0].legend(loc='upper left')\n",
    "\n",
    "#     # Plot the averaged results - subplot 2\n",
    "#     sns.lineplot(x=range(min_length), y=train_loss_avg_shuffled, label='Train Loss', linewidth=2.5, color='#880454', ax=axs[1])\n",
    "#     sns.lineplot(x=range(min_length), y=val_loss_avg_shuffled, label='Val Loss', linewidth=2.5, color='#2596be', ax=axs[1])\n",
    "\n",
    "#     axs[1].set_title('Training and Validation Loss (5-Fold CV)', fontsize=10)\n",
    "#     axs[1].set_xlabel('Epoch', fontsize=10)\n",
    "#     axs[1].set_ylabel('Loss', fontsize=10)\n",
    "#     axs[1].legend(loc='lower left')\n",
    "    \n",
    "    \n",
    "#     experiment_ID = \"4_shuffled_output\"\n",
    "    \n",
    "\n",
    "    plt.savefig(model_results_dir+\"/\"+\"training-validation-accuracy_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    #plot the mean confusion matrix\n",
    "    mean_cm_BPSVMt = np.mean(conf_matrices, axis=0)\n",
    "    \n",
    "    BPSVMt_precision = np.diag(mean_cm_BPSVMt) / np.sum(mean_cm_BPSVMt, axis=0)\n",
    "    BPSVMt_recall = np.diag(mean_cm_shuffled) / np.sum(mean_cm_shuffled, axis=1)\n",
    "    BPSVMt_f1 = 2 * (BPSVMt_precision * BPSVMt_recall) / (BPSVMt_precision + BPSVMt_recall)\n",
    "    \n",
    "    # Create labels with F1-score included\n",
    "    f1_labels_BPSVMMt = [f\"{label}\\n{f1_score:.2f}\" for label, f1_score in zip(train_labels_names, BPSVMt_f1)]\n",
    "\n",
    "#     # Plot mean confusion matrix with F1-score labels\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     ax = sns.heatmap(mean_cm, annot=False, cmap='Blues', fmt='g', )\n",
    "\n",
    "#     plt.title('Mean Confusion Matrix - (5-Fold CV)', fontsize=12)\n",
    "#     plt.xlabel('Predicted Labels', fontsize=10)\n",
    "#     plt.ylabel('True Labels', fontsize=10)\n",
    "#     plt.xticks(rotation=0)\n",
    "#     plt.yticks(rotation=0)\n",
    "#     plt.savefig(\"mean_CM.svg\", bbox_inches='tight', dpi=300)\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    # train_labels_names = ['moving', 'rightTurn', 'immobile', 'grooming', 'still', 'leftTurn']\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(mean_cm, annot=False, cmap='Blues', fmt='g', annot_kws={\"fontsize\": 10}, xticklabels=f1_labels_BPSVMMt, yticklabels=train_labels_names, vmin=np.min(mean_cm), vmax=np.max(mean_cm))\n",
    "    plt.title('Mean Confusion Matrix (5-Fold CV)', fontsize=12)\n",
    "    plt.xlabel('Predicted Labels', fontsize=12)\n",
    "    plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, ha='center', fontsize=7)\n",
    "    plt.ylabel('True Labels', fontsize=12)\n",
    "    plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=7)\n",
    "    plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=600)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # mean_cm_shuffled = np.mean(conf_matrices_shuffled, axis=0)\n",
    "    # # train_labels_names = ['grooming', 'frozen', 'not moving', 'moving', 'right turn', 'left turn']    \n",
    "    # plt.figure(figsize=(7, 5))\n",
    "    # sns.heatmap(mean_cm_shuffled, annot=False, cmap='Blues', fmt='g', vmin=np.min(mean_cm), vmax=np.max(mean_cm))\n",
    "    # plt.title('Mean Confusion Matrix - (5-Fold CV)', fontsize=12)\n",
    "    # plt.xlabel('Predicted Labels', fontsize=10)\n",
    "    # plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    # plt.ylabel('True Labels', fontsize=10)\n",
    "    # plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    # plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=300)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c941d19b-2977-4f9c-b40d-51c2b0c187a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate precision, recall, and F1-score per class label\n",
    "precision = np.diag(mean_cm) / np.sum(mean_cm, axis=0)\n",
    "recall = np.diag(mean_cm) / np.sum(mean_cm, axis=1)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# # Calculate the shuffled precision, recall, and F1-score per class label\n",
    "shuffled_precision = np.diag(mean_cm_shuffled) / np.sum(mean_cm_shuffled, axis=0)\n",
    "shuffled_recall = np.diag(mean_cm_shuffled) / np.sum(mean_cm_shuffled, axis=1)\n",
    "shuffled_f1 = 2 * (shuffled_precision * shuffled_recall) / (shuffled_precision + shuffled_recall)\n",
    "\n",
    "\n",
    "# Calculate the shuffled precision, recall, and F1-score per class label\n",
    "BPSVMt_precision = np.diag(mean_cm_BPSVMt) / np.sum(mean_cm_BPSVMt, axis=0)\n",
    "BPSVMt_recall = np.diag(mean_cm_shuffled) / np.sum(mean_cm_shuffled, axis=1)\n",
    "BPSVMt_f1 = 2 * (BPSVMt_precision * BPSVMt_recall) / (BPSVMt_precision + BPSVMt_recall)\n",
    "\n",
    "# Create bar plot\n",
    "x = np.arange(len(train_labels_names))\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot precision and shuffled precision with a dash line separator\n",
    "# ax.bar(x - width / 2, precision, width, label='Precision', color='cornflowerblue')\n",
    "# ax.bar(x - width / 2, shuffled_precision, width, label='Shuffled Precision', color='royalblue')\n",
    "\n",
    "# # Plot recall and shuffled recall with a dash line separator\n",
    "# ax.bar(x + width / 2, recall, width, label='Recall', color='lightblue')\n",
    "# ax.bar(x + width / 2, shuffled_recall, width, label='Shuffled Recall', color='powderblue')\n",
    "\n",
    "# # Plot F1-score and shuffled F1-score with a dash line separator\n",
    "# ax.bar(x + 3 * width / 2, f1, width, label='F1-Score', color='plum')\n",
    "# ax.bar(x + 3 * width / 2, shuffled_f1, width, label='Shuffled F1-Score', color='thistle')\n",
    "\n",
    "# Plot precision and shuffled precision with a dash line separator\n",
    "# ax.bar(x - width / 2, precision, width, label='Precision', color='cornflowerblue')\n",
    "# ax.bar(x - width / 2, shuffled_precision, width, label='Shuffled Precision', color='cornflowerblue')\n",
    "\n",
    "# # Plot recall and shuffled recall with a dash line separator\n",
    "# ax.bar(x + width / 2, recall, width, label='Recall', color='lightblue')\n",
    "# ax.bar(x + width / 2, shuffled_recall, width, label='Shuffled Recall', color='lightblue')\n",
    "\n",
    "# # Plot F1-score and shuffled F1-score with a dash line separator\n",
    "# ax.bar(x + 3 * width / 2, f1, width, label='F1-Score', color='plum')\n",
    "# ax.bar(x + 3 * width / 2, shuffled_f1, width, label='Shuffled F1-Score', color='plum')\n",
    "\n",
    "\n",
    "# Plot precision and shuffled precision with a dash line separator\n",
    "ax.bar(x - width / 2, precision, width, label='Precision', color='cornflowerblue')\n",
    "ax.bar(x - width / 2, BPSVMt_precision, width, label='BPSVMt Precision', color='royalblue')\n",
    "# ax.bar(x - width / 2, shuffled_precision, width, label='Chance Precision', color='royalblue')\n",
    "\n",
    "# Plot recall and shuffled recall with a dash line separator\n",
    "ax.bar(x + width / 2, recall, width, label='Recall', color='lightblue')\n",
    "ax.bar(x + width / 2, BPSVMt_recall, width, label='BPSVMt Recall', color='powderblue')\n",
    "# ax.bar(x + width / 2, shuffled_recall, width, label='Chance Recall', color='powderblue')\n",
    "\n",
    "# Plot F1-score and shuffled F1-score with a dash line separator\n",
    "ax.bar(x + 3 * width / 2, f1, width, label='F1-Score', color='thistle')\n",
    "ax.bar(x + 3 * width / 2, BPSVMt_f1, width, label='BPSVMt F1-Score', color='plum')\n",
    "# ax.bar(x + 3 * width / 2, shuffled_f1, width, label='Chance F1-Score', color='plum')\n",
    "\n",
    "\n",
    "\n",
    "# # Add numbers on top of each bar\n",
    "# for i, val in enumerate(precision):\n",
    "#     ax.annotate(f\"{val:.2f}\", (x[i] - width / 2, val), ha='center', va='bottom', fontsize=10)\n",
    "# for i, val in enumerate(shuffled_precision):\n",
    "#     ax.annotate(f\"{val:.2f}\", (x[i] - width / 2, val), ha='center', va='bottom', fontsize=10)\n",
    "# for i, val in enumerate(recall):\n",
    "#     ax.annotate(f\"{val:.2f}\", (x[i] + width / 2, val), ha='center', va='bottom', fontsize=10)\n",
    "# for i, val in enumerate(shuffled_recall):\n",
    "#     ax.annotate(f\"{val:.2f}\", (x[i] + width / 2, val), ha='center', va='bottom', fontsize=10)\n",
    "# for i, val in enumerate(f1):\n",
    "#     ax.annotate(f\"{val:.2f}\", (x[i] + 3 * width / 2, val), ha='center', va='bottom', fontsize=10)\n",
    "# for i, val in enumerate(shuffled_f1):\n",
    "#     ax.annotate(f\"{val:.2f}\", (x[i] + 3 * width / 2, val), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.set_title('Mean Precision, Recall, and F1-Score per Behaviour Label (BPNNt & BPNNt-Chance)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Class Label', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(train_labels_names, rotation=0, fontsize=12)\n",
    "\n",
    "# Modify the legend to show only Precision, Recall, and F1-Score\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "legend_handles = [handles[0], handles[1], handles[2], handles[3], handles[4], handles[5]]\n",
    "legend_labels = [labels[0], labels[1], labels[2], labels[3], labels[4], labels[5]]\n",
    "ax.legend(legend_handles, legend_labels)\n",
    "\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e82ee0-6b60-4e22-94a5-c57826c5e70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as n\n",
    "# Calculate precision, recall, and F1-score per class label\n",
    "precision = np.diag(mean_cm) / np.sum(mean_cm, axis=0)\n",
    "recall = np.diag(mean_cm) / np.sum(mean_cm, axis=1)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate the shuffled precision, recall, and F1-score per class label\n",
    "shuffled_precision = np.diag(mean_cm_shuffled) / np.sum(mean_cm_shuffled, axis=0)\n",
    "shuffled_recall = np.diag(mean_cm_shuffled) / np.sum(mean_cm_shuffled, axis=1)\n",
    "shuffled_f1 = 2 * (shuffled_precision * shuffled_recall) / (shuffled_precision + shuffled_recall)\n",
    "\n",
    "# Calculate the BPSVMt precision, recall, and F1-score per class label\n",
    "BPSVMt_precision = np.diag(mean_cm_BPSVMt) / np.sum(mean_cm_BPSVMt, axis=0)\n",
    "BPSVMt_recall = np.diag(mean_cm_BPSVMt) / np.sum(mean_cm_BPSVMt, axis=1)\n",
    "BPSVMt_f1 = 2 * (BPSVMt_precision * BPSVMt_recall) / (BPSVMt_precision + BPSVMt_recall)\n",
    "\n",
    "# Create bar plot\n",
    "x = np.arange(len(train_labels_names))\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot precision and BPSVMt precision with a dash line separator\n",
    "ax.bar(x - width / 2, precision, width, label='Precision')\n",
    "ax.bar(x - width / 2, BPSVMt_precision, width, label='BPSVMt Precision')\n",
    "\n",
    "# Plot recall and BPSVMt recall with a dash line separator\n",
    "ax.bar(x + width / 2, recall, width, label='Recall')\n",
    "ax.bar(x + width / 2, BPSVMt_recall, width, label='BPSVMt Recall')\n",
    "\n",
    "# Plot F1-score and BPSVMt F1-score with a dash line separator\n",
    "ax.bar(x + 3 * width / 2, f1, width, label='F1-Score')\n",
    "ax.bar(x + 3 * width / 2, BPSVMt_f1, width, label='BPSVMt F1-Score')\n",
    "\n",
    "ax.set_title('Mean Precision, Recall, and F1-Score per Behaviour Label (BPNNt & BPNNt-Chance)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Class Label', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(train_labels_names, rotation=0, fontsize=12)\n",
    "\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68895306-2a08-47c5-a238-aa2fac6e6c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d3f76e4-a06d-4d7f-93b0-9f5d9dbd0f7d",
   "metadata": {},
   "source": [
    "## Load BPSVMt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0476d-f22a-488c-9dda-ea60443a06a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_existing_shuffled_data = True\n",
    "\n",
    "if load_existing_shuffled_data:\n",
    "    # Fetch results\n",
    "    model_results_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/Exp_4.3.2-BPSVMt-one-video_output/results\"\n",
    "\n",
    "    with open(os.path.join(model_results_dir, 'cm_avg.pkl'), 'rb') as f:\n",
    "        cm_avg = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'accuracies.pkl'), 'rb') as f:\n",
    "        accuracies = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'losses.pkl'), 'rb') as f:\n",
    "        losses = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_accuracies.pkl'), 'rb') as f:\n",
    "        shuffled_accuracies = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_cm_avg.pkl'), 'rb') as f:\n",
    "        shuffled_cm_avg = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_losses.pkl'), 'rb') as f:\n",
    "        shuffled_losses = pickle.load(f)\n",
    "    # with open(os.path.join(model_results_dir, 'train_labels_names.pkl'), 'rb') as f:\n",
    "    #     train_labels_names = pickle.load(f)\n",
    "\n",
    "    n_splits = 5\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "    # Accuracy and Shuffled Accuracy\n",
    "    ax1 = axs[0, 0]\n",
    "    bar_width = 0.4\n",
    "    index = np.arange(1, n_splits + 1)\n",
    "    ax1.bar(index - bar_width / 2, accuracies, width=bar_width, color='#880454', label='Accuracy')\n",
    "    # ax1.bar(index + bar_width/2, shuffled_accuracies, width=bar_width, color='#2596be', label='Chance Accuracy')\n",
    "    ax1.set_xlabel(\"Fold\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Accuracy\", fontsize=12)\n",
    "    ax1.set_title(\"Accuracy per Fold (5-Fold CV)\")\n",
    "    # ax1.legend()\n",
    "\n",
    "    # # Loss and Shuffled Loss\n",
    "    # ax2 = axs[0, 1]\n",
    "    # ax2.bar(index - bar_width / 2, losses, width=bar_width, color='#880454', label='Loss')\n",
    "    # # ax2.bar(index + bar_width/2, shuffled_losses, width=bar_width, color='#2596be', label='Chance Loss')\n",
    "    # ax2.set_xlabel(\"Fold\", fontsize=12)\n",
    "    # ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "    # ax2.set_title(\"Loss per Fold (5-Fold CV)\")\n",
    "    # # ax2.legend()\n",
    "\n",
    "    # Average Confusion Matrix for Regular Labels\n",
    "    ax3 = axs[1, 0]\n",
    "    # label_names = ['moving', 'rightTurn', 'immobile', 'grooming', 'still', 'leftTurn']\n",
    "    sns.heatmap(np.mean(cm_avg, axis=0), annot=False, cmap='Blues', fmt='g', ax=ax3)\n",
    "    ax3.set_title('Average Confusion Matrix Per Fold (5-Fold CV)')\n",
    "    ax3.set_xlabel('Predicted Labels', fontsize=12)\n",
    "    ax3.set_xticks(np.arange(len(train_labels_names)))\n",
    "    ax3.set_xticklabels(train_labels_names, ha='center', fontsize=8)\n",
    "    ax3.set_ylabel('True Labels', fontsize=12)\n",
    "    ax3.set_yticks(np.arange(len(train_labels_names)))\n",
    "    ax3.set_yticklabels(train_labels_names, rotation=0, fontsize=8)\n",
    "\n",
    "    # # Average Confusion Matrix for Shuffled Labels\n",
    "    # ax4 = axs[1, 1]\n",
    "    # sns.heatmap(np.mean(shuffled_cm_avg, axis=0), annot=False, cmap='Blues', fmt='g', ax=ax4)\n",
    "    # ax4.set_title('Average Confusion Matrix (5-Fold CV - Shuffled Labels)')\n",
    "    # ax4.set_xlabel('Predicted Labels', fontsize=12)\n",
    "    # ax4.set_xticks(np.arange(len(train_labels_names)))\n",
    "    # ax4.set_xticklabels(train_labels_names, ha='center', fontsize=8)\n",
    "    # ax4.set_ylabel('True Labels', fontsize=12)\n",
    "    # ax4.set_yticks(np.arange(len(train_labels_names)))\n",
    "    # ax4.set_yticklabels(train_labels_names, rotation=0, fontsize=8)\n",
    "\n",
    "    plt.tight_layout(pad=3.0)  # Increase spacing between subplots\n",
    "    save_SVM_plots = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/4-BPSVM_output/\"\n",
    "    plt.savefig(save_SVM_plots + \"/accuracy_loss_cm_regular_shuffled_labels.svg\", dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f247a16-70b6-47b9-9cdf-9fc3a6997125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f966ac-4e6f-4e31-8cab-3b40cafc081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cm_bpsvm = np.mean(cm_avg, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043ab07-850b-4f78-9d47-1fb287d68443",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cm_bpsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afac980-b2f9-456f-b825-323ebdb6ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate precision, recall, and F1-score per class label\n",
    "precision = np.diag(mean_cm) / np.sum(mean_cm, axis=0)\n",
    "recall = np.diag(mean_cm) / np.sum(mean_cm, axis=1)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate the shuffled precision, recall, and F1-score per class label\n",
    "shuffled_precision = np.diag(mean_cm_shuffled) / np.sum(mean_cm_shuffled, axis=0)\n",
    "shuffled_recall = np.diag(mean_cm_shuffled) / np.sum(mean_cm_shuffled, axis=1)\n",
    "shuffled_f1 = 2 * (shuffled_precision * shuffled_recall) / (shuffled_precision + shuffled_recall)\n",
    "\n",
    "# Calculate precision, recall, and F1-score per class label for BPSVM\n",
    "bpsvm_precision = np.diag(mean_cm_bpsvm) / np.sum(mean_cm_bpsvm, axis=0)\n",
    "bpsvm_recall = np.diag(mean_cm_bpsvm) / np.sum(mean_cm_bpsvm, axis=1)\n",
    "bpsvm_f1 = 2 * (bpsvm_precision * bpsvm_recall) / (bpsvm_precision + bpsvm_recall)\n",
    "\n",
    "# Create bar plot\n",
    "x = np.arange(len(train_labels_names))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot precision, recall, and F1-score for BPNNt\n",
    "ax.bar(x - width, precision, width, label='BPNNt Precision', color='cornflowerblue')\n",
    "ax.bar(x, recall, width, label='BPNNt Recall', color='lightblue')\n",
    "ax.bar(x + width, f1, width, label='BPNNt F1-Score', color='plum')\n",
    "\n",
    "# # Plot shuffled precision, recall, and F1-score\n",
    "# ax.bar(x - width, shuffled_precision, width, label='BPNNt-Chance Precision', color='cornflowerblue')\n",
    "# ax.bar(x, shuffled_recall, width, label='BPNNt-Chance Recall', color='lightblue')\n",
    "# ax.bar(x + width, shuffled_f1, width, label='BPNNt-Chance F1-Score', color='plum')\n",
    "\n",
    "# Plot precision, recall, and F1-score for BPSVM\n",
    "ax.bar(x - width, bpsvm_precision, width, label='BPSVMt Precision', color='cornflowerblue')\n",
    "ax.bar(x, bpsvm_recall, width, label='BPSVMt Recall', color='lightblue')\n",
    "ax.bar(x + width, bpsvm_f1, width, label='BPSVMt F1-Score', color='plum')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title('Mean Precision, Recall, and F1-Score per Behaviour Label (BPNNt, BPNNt-Chance & BPSVMt)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Class Label', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(train_labels_names, rotation=0, fontsize=12)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"score_bar_plot.svg\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b435a0-dba6-4b01-a220-9e4665200a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_list = []\n",
    "# for conf_matrix in cm_avg:\n",
    "#     precision = np.diag(conf_matrix) / np.sum(conf_matrix, axis=0)\n",
    "#     recall = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "#     f1 = 2 * (precision * recall) / (precision + recall)\n",
    "#     f1_list.append(np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad0428-6d11-48d6-a0df-8bda93cf371a",
   "metadata": {},
   "source": [
    "## Plot BPSVM and Chance level new plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c621d-02c2-4746-b631-5455e0b4f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_existing_shuffled_data = True\n",
    "\n",
    "if load_existing_shuffled_data:\n",
    "    # Fetch results\n",
    "    model_results_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/Exp_4.3_BPSVMt_multiple_videos_output/results\"\n",
    "\n",
    "    with open(os.path.join(model_results_dir, 'cm_avg.pkl'), 'rb') as f:\n",
    "        cm_avg = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'accuracies.pkl'), 'rb') as f:\n",
    "        accuracies = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'losses.pkl'), 'rb') as f:\n",
    "        losses = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_accuracies.pkl'), 'rb') as f:\n",
    "        shuffled_accuracies = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_cm_avg.pkl'), 'rb') as f:\n",
    "        shuffled_cm_avg = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_losses.pkl'), 'rb') as f:\n",
    "        shuffled_losses = pickle.load(f)\n",
    "    # with open(os.path.join(model_results_dir, 'train_labels_names.pkl'), 'rb') as f:\n",
    "    #     train_labels_names = pickle.load(f)\n",
    "\n",
    "    n_splits = 5\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "    # Accuracy and Shuffled Accuracy\n",
    "    ax1 = axs[0, 0]\n",
    "    bar_width = 0.4\n",
    "    index = np.arange(1, n_splits + 1)\n",
    "    ax1.bar(index - bar_width / 2, accuracies, width=bar_width, color='#880454', label='Accuracy')\n",
    "    ax1.bar(index + bar_width/2, shuffled_accuracies, width=bar_width, color='#2596be', label='Chance Accuracy')\n",
    "    ax1.set_xlabel(\"Fold\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Accuracy\", fontsize=12)\n",
    "    ax1.set_title(\"Accuracy per Fold (5-Fold CV)\")\n",
    "    ax1.legend(loc=\"lower left\")\n",
    "\n",
    "    # Loss and Shuffled Loss\n",
    "    ax2 = axs[0, 1]\n",
    "    ax2.bar(index - bar_width / 2, losses, width=bar_width, color='#880454', label='Loss')\n",
    "    ax2.bar(index + bar_width/2, shuffled_losses, width=bar_width, color='#2596be', label='Chance Loss')\n",
    "    ax2.set_xlabel(\"Fold\", fontsize=12)\n",
    "    ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "    ax2.set_title(\"Loss per Fold (5-Fold CV)\")\n",
    "    ax2.legend(loc=\"lower left\")\n",
    "    \n",
    "    #Mean CM:\n",
    "    mean_cm_bpsvm = np.mean(cm_avg, axis=0)    \n",
    "    \n",
    "    \n",
    "    # Calculate precision, recall, and F1-score per class label\n",
    "    bpsvm_precision = np.diag(mean_cm_bpsvm) / np.sum(mean_cm_bpsvm, axis=0)\n",
    "    bpsvm_recall = np.diag(mean_cm_bpsvm) / np.sum(mean_cm_bpsvm, axis=1)\n",
    "    f1 = 2 * (bpsvm_precision * bpsvm_recall) / (bpsvm_precision + bpsvm_recall)\n",
    "    \n",
    "    # Create labels with F1-score included\n",
    "    f1_labels = [f\"{label}\\n{f1_score:.2f}\" for label, f1_score in zip(train_labels_names, f1)]\n",
    "\n",
    "    \n",
    "    # Average Confusion Matrix for Regular Labels\n",
    "    ax3 = axs[1, 0]\n",
    "    # label_names = ['moving', 'rightTurn', 'immobile', 'grooming', 'still', 'leftTurn']\n",
    "    sns.heatmap(np.mean(cm_avg, axis=0), annot=False, cmap='Blues', fmt='g', ax=ax3, vmin=np.min(cm_avg), vmax=np.max(cm_avg))\n",
    "    ax3.set_title('Average Confusion Matrix Per Fold (5-Fold CV)')\n",
    "    ax3.set_xlabel('Predicted Labels', fontsize=12)\n",
    "    ax3.set_xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=12)\n",
    "    ax3.set_xticklabels(train_labels_names, ha='center', fontsize=8)\n",
    "    ax3.set_ylabel('True Labels', fontsize=12)\n",
    "    ax3.set_yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=12)\n",
    "    ax3.set_yticklabels(train_labels_names, rotation=0, fontsize=8)\n",
    "    \n",
    "    # add the F1-score below:\n",
    "\n",
    "    # Average Confusion Matrix for Shuffled Labels\n",
    "    ax4 = axs[1, 1]\n",
    "    sns.heatmap(np.mean(shuffled_cm_avg, axis=0), annot=False, cmap='Blues', fmt='g', ax=ax4, vmin=np.min(cm_avg), vmax=np.max(cm_avg))\n",
    "    ax4.set_title('Average Confusion Matrix (5-Fold CV - Shuffled Labels)')\n",
    "    ax4.set_xlabel('Predicted Labels', fontsize=12)\n",
    "    ax4.set_xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=12)\n",
    "    ax4.set_xticklabels(train_labels_names, ha='center', fontsize=8)\n",
    "    ax4.set_ylabel('True Labels', fontsize=12)\n",
    "    ax4.set_yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=12)\n",
    "    ax4.set_yticklabels(train_labels_names, rotation=0, fontsize=8)\n",
    "\n",
    "    plt.tight_layout(pad=3.0)  # Increase spacing between subplots\n",
    "    save_SVM_plots = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/4-BPSVM_output/\"\n",
    "    plt.savefig(save_SVM_plots + \"/accuracy_loss_cm_regular_shuffled_labels.svg\", dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    # mean_cm_shuffled = np.mean(shuffled_cm_avg, axis=0)\n",
    "    # train_labels_names = ['grooming', 'frozen', 'not moving', 'moving', 'right turn', 'left turn']    \n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # sns.heatmap(mean_cm_shuffled, annot=False, cmap='Blues', fmt='g')\n",
    "    # plt.title('Mean Confusion Matrix - (5-Fold CV)', fontsize=12)\n",
    "    # plt.xlabel('Predicted Labels', fontsize=10)\n",
    "    # plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    # plt.ylabel('True Labels', fontsize=10)\n",
    "    # plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    # plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=300)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fcee30-531b-4812-a7bb-9b624c32ed19",
   "metadata": {},
   "source": [
    "## Plot BPSVMt and Chance level new plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f493a9-ad48-41ea-908a-0fa96ffb2d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_existing_shuffled_data = True\n",
    "\n",
    "if load_existing_shuffled_data:\n",
    "    # Fetch results\n",
    "    model_results_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/Exp_4.3_BPSVMt_one_video_output/results\" #Exp_3.3-BPSVM-multiple-videos_output/results\n",
    "\n",
    "    with open(os.path.join(model_results_dir, 'cm_avg.pkl'), 'rb') as f:\n",
    "        cm_avg = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'accuracies.pkl'), 'rb') as f:\n",
    "        accuracies = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'losses.pkl'), 'rb') as f:\n",
    "        losses = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_accuracies.pkl'), 'rb') as f:\n",
    "        shuffled_accuracies = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_cm_avg.pkl'), 'rb') as f:\n",
    "        shuffled_cm_avg = pickle.load(f)\n",
    "    with open(os.path.join(model_results_dir, 'shuffled_losses.pkl'), 'rb') as f:\n",
    "        shuffled_losses = pickle.load(f)\n",
    "    # with open(os.path.join(model_results_dir, 'train_labels_names.pkl'), 'rb') as f:\n",
    "    #     train_labels_names = pickle.load(f)\n",
    "\n",
    "    n_splits = 5\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "    # Accuracy and Shuffled Accuracy\n",
    "    ax1 = axs[0, 0]\n",
    "    bar_width = 0.4\n",
    "    index = np.arange(1, n_splits + 1)\n",
    "    ax1.bar(index - bar_width / 2, accuracies, width=bar_width, color='#880454', label='Accuracy')\n",
    "    ax1.bar(index + bar_width/2, shuffled_accuracies, width=bar_width, color='#2596be', label='Chance Accuracy')\n",
    "    ax1.set_xlabel(\"Fold\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Accuracy\", fontsize=12)\n",
    "    ax1.set_title(\"Accuracy per Fold (5-Fold CV)\")\n",
    "    ax1.legend()\n",
    "\n",
    "    # Loss and Shuffled Loss\n",
    "    ax2 = axs[0, 1]\n",
    "    ax2.bar(index - bar_width / 2, losses, width=bar_width, color='#880454', label='Loss')\n",
    "    ax2.bar(index + bar_width/2, shuffled_losses, width=bar_width, color='#2596be', label='Chance Loss')\n",
    "    ax2.set_xlabel(\"Fold\", fontsize=12)\n",
    "    ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "    ax2.set_title(\"Loss per Fold (5-Fold CV)\")\n",
    "    ax2.legend(loc='lower left')\n",
    "    \n",
    "    #Mean CM:\n",
    "    # mean_cm_bpsvm = np.mean(cm_avg, axis=0)    \n",
    "    \n",
    "    \n",
    "    # Calculate precision, recall, and F1-score per class label\n",
    "    # bpsvm_precision = np.diag(cm_avg) / np.sum(cm_avg, axis=0)\n",
    "    # bpsvm_recall = np.diag(cm_avg) / np.sum(cm_avg, axis=1)\n",
    "    # f1 = 2 * (bpsvm_precision * bpsvm_recall) / (bpsvm_precision + bpsvm_recall)\n",
    "    \n",
    "#     # Create labels with F1-score included\n",
    "#     f1_labels = [f\"{label}\\n{f1_score:.2f}\" for label, f1_score in zip(train_labels_names, f1)]\n",
    "\n",
    "    \n",
    "    # Average Confusion Matrix for Regular Labels\n",
    "    ax3 = axs[1, 0]\n",
    "    # label_names = ['moving', 'rightTurn', 'immobile', 'grooming', 'still', 'leftTurn']\n",
    "    sns.heatmap(np.mean(cm_avg, axis=0), annot=False, cmap='Blues', fmt='g', ax=ax3, vmin=np.min(cm_avg), vmax=np.max(cm_avg))\n",
    "    ax3.set_title('Average Confusion Matrix Per Fold (5-Fold CV)')\n",
    "    ax3.set_xlabel('Predicted Labels', fontsize=12)\n",
    "    ax3.set_xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=12)\n",
    "    ax3.set_xticklabels(train_labels_names, ha='center', fontsize=8)\n",
    "    ax3.set_ylabel('True Labels', fontsize=12)\n",
    "    ax3.set_yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=12)\n",
    "    ax3.set_yticklabels(train_labels_names, rotation=0, fontsize=8)\n",
    "    \n",
    "    # add the F1-score below:\n",
    "\n",
    "    # Average Confusion Matrix for Shuffled Labels\n",
    "    ax4 = axs[1, 1]\n",
    "    sns.heatmap(np.mean(shuffled_cm_avg, axis=0), annot=False, cmap='Blues', fmt='g', ax=ax4, vmin=np.min(cm_avg), vmax=np.max(cm_avg))\n",
    "    ax4.set_title('Average Confusion Matrix (5-Fold CV - Shuffled Labels)')\n",
    "    ax4.set_xlabel('Predicted Labels', fontsize=12)\n",
    "    ax4.set_xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=12)\n",
    "    ax4.set_xticklabels(train_labels_names, ha='center', fontsize=8)\n",
    "    ax4.set_ylabel('True Labels', fontsize=12)\n",
    "    ax4.set_yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=12)\n",
    "    ax4.set_yticklabels(train_labels_names, rotation=0, fontsize=8)\n",
    "\n",
    "    plt.tight_layout(pad=3.0)  # Increase spacing between subplots\n",
    "    save_SVM_plots = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/4-BPSVM_output/\"\n",
    "    plt.savefig(save_SVM_plots + \"/accuracy_loss_cm_regular_shuffled_labels.svg\", dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #    mean_cm_shuffled = np.mean(conf_matrices_shuffled, axis=0)\n",
    "    # train_labels_names = ['grooming', 'frozen', 'not moving', 'moving', 'right turn', 'left turn']    \n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # sns.heatmap(mean_cm_shuffled, annot=False, cmap='Blues', fmt='g')\n",
    "    # plt.title('Mean Confusion Matrix - (5-Fold CV)', fontsize=12)\n",
    "    # plt.xlabel('Predicted Labels', fontsize=10)\n",
    "    # plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    # plt.ylabel('True Labels', fontsize=10)\n",
    "    # plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    # plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=300)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff28860-2505-451b-a94d-2645c91c5b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17231736-d13a-47ad-828b-ef07a0b3eca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2155b-51b2-47a3-bbd2-9bd7f8ae553d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8813e51-497f-4d43-83ee-4145a3ec288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Plotting\n",
    "#     n_splits = 5\n",
    "\n",
    "#     plt.figure(figsize=(12, 10))\n",
    "\n",
    "#     # Accuracy and Shuffled Accuracy\n",
    "#     plt.subplot(2, 2, 1)\n",
    "#     sns.lineplot(x=np.arange(1, n_splits+1), y=accuracies, marker='o', label='Accuracy')\n",
    "#     sns.lineplot(x=np.arange(1, n_splits+1), y=shuffled_accuracies, marker='o', label='Chance Accuracy')\n",
    "#     plt.xlabel(\"Fold\", fontsize=12)\n",
    "#     plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "#     plt.title(\"Accuracy per Fold (5-Fold CV) \")\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Loss and Shuffled Loss\n",
    "#     plt.subplot(2, 2, 2)\n",
    "#     sns.lineplot(x=np.arange(1, n_splits+1), y=losses, marker='o', label='Loss')\n",
    "#     sns.lineplot(x=np.arange(1, n_splits+1), y=shuffled_losses, marker='o', label='Chance Loss')\n",
    "#     plt.xlabel(\"Fold\", fontsize=12)\n",
    "#     plt.ylabel(\"Loss\", fontsize=12)\n",
    "#     plt.title(\"Loss per Fold (5-Fold CV)\")\n",
    "#     plt.legend()\n",
    "\n",
    "#     # Average Confusion Matrix for Regular Labels\n",
    "#     plt.subplot(2, 2, 3)\n",
    "#     train_labels_names = ['moving', 'rightTurn', 'immobile', 'grooming', 'still', 'leftTurn']\n",
    "#     sns.heatmap(np.mean(cm_avg, axis=0), annot=True, cmap='Blues', fmt='g')\n",
    "#     plt.title('Average Confusion Matrix Per Fold (5-Fold CV)')\n",
    "#     plt.xlabel('Predicted Labels', fontsize=12)\n",
    "#     plt.xticks(np.arange(len(label_names)) + 0.5, label_names, ha='center', fontsize=8)\n",
    "#     plt.ylabel('True Labels', fontsize=12)\n",
    "#     plt.yticks(np.arange(len(label_names)) + 0.5, label_names, rotation=0, fontsize=8)\n",
    "\n",
    "#     # Average Confusion Matrix for Shuffled Labels\n",
    "#     plt.subplot(2, 2, 4)\n",
    "#     sns.heatmap(np.mean(shuffled_cm_avg, axis=0), annot=True, cmap='Blues', fmt='g')\n",
    "#     plt.title('Average Confusion Matrix (5-Fold CV - Shuffled Labels)')\n",
    "#     plt.xlabel('Predicted Labels', fontsize=12)\n",
    "#     plt.xticks(np.arange(len(label_names)) + 0.5, label_names, ha='center', fontsize=8)\n",
    "#     plt.ylabel('True Labels', fontsize=12)\n",
    "#     plt.yticks(np.arange(len(label_names)) + 0.5, label_names, rotation=0, fontsize=8)\n",
    "\n",
    "\n",
    "#     save_SVM_plots = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/4-BPSVM_output/\"\n",
    "#     plt.savefig(save_SVM_plots+\"/accuracy_loss_cm_regular_shuffled_labels.svg\", dpi=600, bbox_inches='tight')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(4, 3))\n",
    "#     sns.set_style('whitegrid')\n",
    "#     sns.set_palette('husl')\n",
    "    \n",
    "#     min_length = len(val_loss_avg)\n",
    "    \n",
    "#     # Plot the averaged results\n",
    "#     sns.lineplot(x=range(min_length), y=train_acc_avg, label='Train Acc', linewidth=2.5, color='#880454')\n",
    "#     sns.lineplot(x=range(min_length), y=val_acc_avg, label='Val Acc', linewidth=2.5, color='#2596be')\n",
    "    \n",
    "#     plt.title('Training and Validation Accuracy (5-Fold CV)', fontsize=8)\n",
    "#     plt.xlabel('Epoch', fontsize=6)\n",
    "#     plt.ylabel('Accuracy', fontsize=6)\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.savefig(model_acc_dir+\"/\"+\"training-validation-accuracy_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Plot the averaged results\n",
    "#     sns.lineplot(x=range(min_length), y=train_loss_avg, label='Train Loss', linewidth=2.5, color='#880454')\n",
    "#     sns.lineplot(x=range(min_length), y=val_loss_avg, label='Val Loss', linewidth=2.5, color='#2596be')\n",
    "    \n",
    "#     plt.title('Training and Validation Loss (5-Fold CV)', fontsize=8)\n",
    "#     plt.xlabel('Epoch', fontsize=6)\n",
    "#     plt.ylabel('Loss', fontsize=6)\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.savefig(model_loss_dir+\"/\"+\"training-validation-loss_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065608a-f197-439d-a0d7-0c0de07cc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d2f72-2ecf-4f41-85f7-3dfb0b1e3a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "else:\n",
    "    \n",
    "    \n",
    "    %store -r train_loss_all\n",
    "    %store -r val_loss_all\n",
    "    %store -r train_acc_all\n",
    "    %store -r val_acc_all\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 3)) \n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_palette('husl')\n",
    "    \n",
    "#     # Find the minimum length of the train and validation accuracy lists\n",
    "    min_length = min([len(train_acc_all[i]) for i in range(num_folds)] + [len(val_acc_all[i]) for i in range(num_folds)])\n",
    "    \n",
    "    # Create arrays to hold the averaged results\n",
    "    train_acc_avg = np.zeros(min_length)\n",
    "    val_acc_avg = np.zeros(min_length)\n",
    "    \n",
    "    \n",
    "    # Average the results across all folds\n",
    "    for i in range(num_folds):\n",
    "        train_acc_fold = np.array(train_acc_all[i][:min_length])\n",
    "        val_acc_fold = np.array(val_acc_all[i][:min_length])\n",
    "        train_acc_avg += train_acc_fold\n",
    "        val_acc_avg += val_acc_fold\n",
    "        \n",
    "        # # Plot individual fold results\n",
    "        # sns.lineplot(x=range(min_length), y=train_acc_fold, label=f'Train Acc Fold {i+1}', alpha=0.7)\n",
    "        # sns.lineplot(x=range(min_length), y=val_acc_fold, label=f'Val Acc Fold {i+1}', alpha=0.7)\n",
    "        \n",
    "    train_acc_avg /= num_folds\n",
    "    val_acc_avg /= num_folds\n",
    "    \n",
    "    # Plot the averaged results\n",
    "    sns.lineplot(x=range(min_length), y=train_acc_avg, label='Train Acc', linewidth=2.5, color='#880454')\n",
    "    sns.lineplot(x=range(min_length), y=val_acc_avg, label='Val Acc', linewidth=2.5, color='#2596be')\n",
    "    \n",
    "    plt.title('Training and Validation Accuracy (5-Fold CV)', fontsize=10)\n",
    "    plt.xlabel('Epoch', fontsize=8)\n",
    "    plt.ylabel('Accuracy', fontsize=8)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.savefig(model_acc_dir+\"/\"+\"training-validation-accuracy_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    #### loss ####\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.set_palette('husl')\n",
    "    \n",
    "    \n",
    "    # Create arrays to hold the averaged results\n",
    "    train_loss_avg = np.zeros(min_length)\n",
    "    val_loss_avg = np.zeros(min_length)\n",
    "    \n",
    "    # Average the results across all folds\n",
    "    for i in range(num_folds):\n",
    "        train_loss_fold = np.array(train_loss_all[i][:min_length])\n",
    "        val_loss_fold = np.array(val_loss_all[i][:min_length])\n",
    "        train_loss_avg += train_loss_fold\n",
    "        val_loss_avg += val_loss_fold\n",
    "        \n",
    "        # # Plot individual fold results\n",
    "        # sns.lineplot(x=range(min_length), y=train_loss_fold, label=f'Train Loss Fold {i+1}', alpha=0.7)\n",
    "        # sns.lineplot(x=range(min_length), y=val_loss_fold, label=f'Val Loss Fold {i+1}', alpha=0.7)\n",
    "    \n",
    "    train_loss_avg /= num_folds\n",
    "    val_loss_avg /= num_folds\n",
    "    \n",
    "    # Plot the averaged results\n",
    "    sns.lineplot(x=range(min_length), y=train_loss_avg, label='Train Loss', linewidth=2.5, color='#880454')\n",
    "    sns.lineplot(x=range(min_length), y=val_loss_avg, label='Val Loss', linewidth=2.5, color='#2596be')\n",
    "    \n",
    "    \n",
    "    model_loss_dir = dir_path\n",
    "    plt.title('Training and Validation Loss (5-Fold CV)', fontsize=10)\n",
    "    plt.xlabel('Epoch', fontsize=8)\n",
    "    plt.ylabel('Loss', fontsize=8)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.savefig(model_loss_dir+\"/\"+\"training-validation-loss_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    mean_cm = np.mean(conf_matrices, axis=0)\n",
    "    train_labels_names = ['grooming', 'frozen', 'not moving', 'moving', 'right turn', 'left turn']    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(mean_cm, annot=False, cmap='Blues', fmt='g')\n",
    "    plt.title('Mean Confusion Matrix - (5-Fold CV)', fontsize=12)\n",
    "    plt.xlabel('Predicted Labels', fontsize=10)\n",
    "    plt.xticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    plt.ylabel('True Labels', fontsize=10)\n",
    "    plt.yticks(np.arange(len(train_labels_names)) + 0.5, train_labels_names, rotation=0, fontsize=10)\n",
    "    plt.savefig(\"mean_CM\"+str(experiment_ID)+'.svg', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # return train_acc_avg, val_acc_avg\n",
    "    \n",
    "#     # Find the minimum length of the train and validation accuracy lists\n",
    "#     min_length_1 = min([len(train_acc_all[i]) for i in range(num_folds)] + [len(val_acc_all[i]) for i in range(num_folds)])\n",
    "#     min_length_2 = min([len(train_loss_all[i]) for i in range(num_folds)] + [len(val_loss_all[i]) for i in range(num_folds)])\n",
    "    \n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "#     sns.set_style('whitegrid')\n",
    "#     sns.set_palette('husl')\n",
    "\n",
    "#     min_length = min([min_length_1] + [min_length_2])\n",
    "    \n",
    "#     print(train_acc_avg)\n",
    "#     print(val_acc_avg)\n",
    "#     print(train_loss_avg)\n",
    "#     print(val_loss_avg)\n",
    "\n",
    "#     # Plot the averaged results - subplot 1\n",
    "#     sns.lineplot(x=range(min_length), y=train_acc_avg, label='Train Acc', linewidth=2.5, color='#880454', ax=axs[0])\n",
    "#     sns.lineplot(x=range(min_length), y=val_acc_avg, label='Val Acc', linewidth=2.5, color='#2596be', ax=axs[0])\n",
    "\n",
    "#     axs[0].set_title('Training and Validation Accuracy (5-Fold CV)', fontsize=8)\n",
    "#     axs[0].set_xlabel('Epoch', fontsize=6)\n",
    "#     axs[0].set_ylabel('Accuracy', fontsize=6)\n",
    "#     axs[0].legend(loc='lower right')\n",
    "\n",
    "#     # Plot the averaged results - subplot 2\n",
    "#     sns.lineplot(x=range(min_length), y=train_loss_avg, label='Train Loss', linewidth=2.5, color='#880454', ax=axs[1])\n",
    "#     sns.lineplot(x=range(min_length), y=val_loss_avg, label='Val Loss', linewidth=2.5, color='#2596be', ax=axs[1])\n",
    "\n",
    "#     axs[1].set_title('Training and Validation Loss (5-Fold CV)', fontsize=8)\n",
    "#     axs[1].set_xlabel('Epoch', fontsize=6)\n",
    "#     axs[1].set_ylabel('Loss', fontsize=6)\n",
    "#     axs[1].legend(loc='lower right')\n",
    "\n",
    "#     plt.savefig(model_acc_dir+\"/\"+\"training-validation-accuracy_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f4d58-7b52-4d48-a834-d4258db4da8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce6dc9-5ea0-4eca-90a6-728cb0ab5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_acc_avg, val_acc_avg = plot_accuracy_k_fold(experiment_ID, model_acc_dir, train_acc_all, val_acc_all, num_folds=num_folds, num_epochs=epochs, min_length=min_length)\n",
    "# train_loss_avg, val_loss_avg = plot_loss_k_fold(experiment_ID, model_loss_dir, train_loss_all, val_loss_all, num_folds=num_folds, num_epochs=epochs, min_length=min_length)\n",
    "\n",
    "# mean_train_acc, mean_val_acc = plot_average_accuracy_k_fold(experiment_ID, model_average_acc_dir, train_acc_all, val_acc_all, num_folds=num_folds, num_epochs=epochs)\n",
    "# mean_train_loss, mean_val_loss = plot_average_loss_k_fold(experiment_ID, model_average_loss_dir, train_loss_all, val_loss_all, num_folds=num_folds, num_epochs=epochs)\n",
    "\n",
    "# f1_score_val = plot_confusion_matrix(experiment_ID, no_of_behaviors, train_labels, val_labels, train_images, val_images, model_cm_dir, model_path, model_version)\n",
    "# plot_loss(experiment_ID, history, model_loss_dir)\n",
    "# plot_accuracy(experiment_ID, history, model_acc_dir)\n",
    "# no_of_behaviors = ['Main Corr', 'Left Corr', 'Right Corr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6532af4f-7315-4e86-8769-a29124c39311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6401bab-19ff-4bb6-adb7-5bbf976d2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49828c8-b814-48b2-8fd6-e29ffb971be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbcba72-6a61-4f1b-92a7-ecce0e57457e",
   "metadata": {},
   "source": [
    "### Save averages from plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7787f104-c56e-4f0e-8260-630166ffdeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pickles directory\n",
    "dir_name_pickles = os.path.join(output_dir, 'results')\n",
    "if not os.path.exists(dir_name_pickles):\n",
    "    os.mkdir(dir_name_pickles)\n",
    "\n",
    "# save pickle files\n",
    "with open(os.path.join(dir_name_pickles, 'train_acc_avg.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_acc_avg, f)\n",
    "\n",
    "with open(os.path.join(dir_name_pickles, 'val_acc_avg.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_acc_avg, f)\n",
    "\n",
    "with open(os.path.join(dir_name_pickles, 'train_loss_avg.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_loss_avg, f)\n",
    "\n",
    "with open(os.path.join(dir_name_pickles, 'val_loss_avg.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_loss_avg, f)\n",
    "    \n",
    "    \n",
    "with open(os.path.join(dir_name_pickles, 'conf_matrices.pkl'), 'wb') as f:\n",
    "    pickle.dump(conf_matrices, f)\n",
    "\n",
    "with open(os.path.join(dir_name_pickles, 'train_labels_names.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_labels_names, f)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec04430-0639-4414-93eb-f453c5e844d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca12244-657a-4c14-a7de-d835f25b3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f19310-486e-4290-b398-12c98ce76cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff50bff-f1d8-4ad3-8777-5ab106c148e1",
   "metadata": {},
   "source": [
    "### Plot the averages across labels for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e7581-ee07-4acb-b577-800fcc28be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all labels:\n",
    "dir_path_all = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/1_output/results\"\n",
    "with open(os.path.join(dir_path_all,'val_loss_avg.pkl'), 'rb') as f:\n",
    "    val_loss_avg_1 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_all,'val_acc_avg.pkl'), 'rb') as f:\n",
    "    val_acc_avg_1 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_all,'train_loss_avg.pkl'), 'rb') as f:\n",
    "    train_loss_avg_1 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_all,'train_acc_avg.pkl'), 'rb') as f:\n",
    "    train_acc_avg_1 = pickle.load(f)\n",
    "\n",
    "\n",
    "# For merged labels:\n",
    "dir_path_merged = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/2_output/results\"\n",
    "with open(os.path.join(dir_path_merged,'val_loss_avg.pkl'), 'rb') as f:\n",
    "    val_loss_avg_2 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_merged,'val_acc_avg.pkl'), 'rb') as f:\n",
    "    val_acc_avg_2 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_merged,'train_loss_avg.pkl'), 'rb') as f:\n",
    "    train_loss_avg_2 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_merged,'train_acc_avg.pkl'), 'rb') as f:\n",
    "    train_acc_avg_2 = pickle.load(f)\n",
    "    \n",
    "    \n",
    "# For new labels:\n",
    "dir_path_new = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/3_output/results\"\n",
    "with open(os.path.join(dir_path_new,'val_loss_avg.pkl'), 'rb') as f:\n",
    "    val_loss_avg_3 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_new,'val_acc_avg.pkl'), 'rb') as f:\n",
    "    val_acc_avg_3 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_new,'train_loss_avg.pkl'), 'rb') as f:\n",
    "    train_loss_avg_3 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(dir_path_new,'train_acc_avg.pkl'), 'rb') as f:\n",
    "    train_acc_avg_3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca3dbc-e8e4-4a96-95f8-d7d0a7113e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the minimum length of the train and validation accuracy lists\n",
    "min_length = min([len(train_acc_avg_1) for i in range(num_folds)] \n",
    "                 + [len(val_acc_avg_1) for i in range(num_folds)] \n",
    "                 + [len(train_acc_avg_2) for i in range(num_folds)] \n",
    "                 + [len(val_acc_avg_2) for i in range(num_folds)] \n",
    "                 + [len(train_acc_avg_3) for i in range(num_folds)] \n",
    "                 + [len(val_acc_avg_3) for i in range(num_folds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f64e8b2-8bb2-4a76-ba2e-bedb1f2b85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_length = len(val_loss_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb36bca9-5d6d-4a47-ae46-5d53c05e3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = min([len(train_loss_avg_1) for i in range(num_folds)] \n",
    "                 + [len(val_loss_avg_1) for i in range(num_folds)] \n",
    "                 + [len(train_loss_avg_2) for i in range(num_folds)] \n",
    "                 + [len(val_loss_avg_2) for i in range(num_folds)] \n",
    "                 + [len(train_loss_avg_3) for i in range(num_folds)] \n",
    "                 + [len(val_loss_avg_3) for i in range(num_folds)]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd6a09-8920-4f32-8fad-a04d5687767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_acc_avg_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912db99-c14d-40ff-95a5-b43264e90eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 7))\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# min_length = len(val_loss_avg)\n",
    "\n",
    "# Plot the averaged results - subplot 1\n",
    "sns.lineplot(x=range(min_length), y=train_acc_avg_1, label='Train Acc All Labels', linewidth=2.5, color='#1E90FF', ax=axs[0])\n",
    "sns.lineplot(x=range(min_length), y=val_acc_avg_1, label='Val Acc All Labels', linewidth=2.5, color='#00BFFF', ax=axs[0])\n",
    "sns.lineplot(x=range(min_length), y=train_acc_avg_2, label='Train Acc 3 Labels', linewidth=2.5, color='#C71585', ax=axs[0])\n",
    "sns.lineplot(x=range(min_length), y=val_acc_avg_2, label='Val Acc 3 Labels', linewidth=2.5, color='#FF00FF', ax=axs[0])\n",
    "sns.lineplot(x=range(min_length), y=train_acc_avg_3[:-1], label='Train Acc 6 Labels', linewidth=2.5, color='#808080', ax=axs[0])\n",
    "sns.lineplot(x=range(min_length), y=val_acc_avg_3[:-1], label='Val Acc 6 Labels', linewidth=2.5, color='#A9A9A9', ax=axs[0])\n",
    "\n",
    "axs[0].set_title('Training and Validation Accuracy (5-Fold CV)', fontsize=12)\n",
    "axs[0].set_xlabel('Epoch', fontsize=8)\n",
    "axs[0].set_ylabel('Accuracy', fontsize=8)\n",
    "axs[0].legend(loc='lower right')\n",
    "\n",
    "# # Plot the averaged results - subplot 2\n",
    "# sns.lineplot(x=range(min_length), y=train_loss_avg, label='Train Loss', linewidth=2.5, color='#880454', ax=axs[1])\n",
    "# sns.lineplot(x=range(min_length), y=val_loss_avg, label='Val Loss', linewidth=2.5, color='#2596be', ax=axs[1])\n",
    "\n",
    "# axs[1].set_title('Training and Validation Loss (5-Fold CV)', fontsize=8)\n",
    "# axs[1].set_xlabel('Epoch', fontsize=6)\n",
    "# axs[1].set_ylabel('Loss', fontsize=6)\n",
    "# axs[1].legend(loc='lower right')\n",
    "\n",
    "# Plot the averaged results - subplot 2\n",
    "sns.lineplot(x=range(min_length), y=train_loss_avg_1, label='Train Loss All Labels', linewidth=2.5, color='#1E90FF', ax=axs[1])\n",
    "sns.lineplot(x=range(min_length), y=val_loss_avg_1, label='Val Loss All Labels', linewidth=2.5, color='#00BFFF', ax=axs[1])\n",
    "sns.lineplot(x=range(min_length), y=train_loss_avg_2, label='Train Loss 3 Labels', linewidth=2.5, color='#C71585', ax=axs[1])\n",
    "sns.lineplot(x=range(min_length), y=val_loss_avg_2, label='Val Loss 3 Labels', linewidth=2.5, color='#FF00FF', ax=axs[1])\n",
    "sns.lineplot(x=range(min_length), y=train_loss_avg_3[:-1], label='Train Loss 6 Labels', linewidth=2.5, color='#808080', ax=axs[1])\n",
    "sns.lineplot(x=range(min_length), y=val_loss_avg_3[:-1], label='Val Loss 6 Labels', linewidth=2.5, color='#A9A9A9', ax=axs[1])\n",
    "\n",
    "axs[1].set_title('Training and Validation Loss (5-Fold CV)', fontsize=12)\n",
    "axs[1].set_xlabel('Epoch', fontsize=8)\n",
    "axs[1].set_ylabel('Accuracy', fontsize=8)\n",
    "axs[1].legend(loc='upper left')\n",
    "\n",
    "plt.savefig(model_acc_dir+\"/\"+\"training-validation-accuracy-loss-accross-labels_\"+str(experiment_ID)+\".svg\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d81209-db2a-460a-9b5a-b083279061fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446f593f-5b10-42f5-8240-507eeda53bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot f-score:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f471d-e943-486d-9fdc-0cf6167f4e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291139e0-d4e8-4a06-a0b2-d39207025289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfebc7d7-52ff-4e40-84cd-850b9e6c830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a4e7a-d077-41db-9582-992323737245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4a55fe1-c869-41f6-8b7f-0cb46a03609b",
   "metadata": {},
   "source": [
    "### Save model info in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff570462-a33b-40e5-8d53-56aa666a4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store -r model\n",
    "# %store -r history\n",
    "# %store -r video_name\n",
    "%store -r comment\n",
    "%store -r experiment_ID\n",
    "\n",
    "%store -r f1_score_val_list\n",
    "%store -r f1_score_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adbc6a7-8443-434d-bfd0-cd32c271b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_training_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d90c2b-53af-427c-ad5b-72373aaeee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_training_info(model=model, history=history, video_name=video_name, comment=comment, experiment_ID=experiment_ID, save_dir=save_dir, f1_score=f1_score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b0c1c-636b-4d86-93b3-a0c97f3066fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6613338-ab42-4768-9219-bb4a4a4a0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bf0457-74ce-4eff-bfad-55a0f2fec885",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_training_info(experiment_ID=experiment_ID,\n",
    "                   data_file = data_file,\n",
    "                   no_of_labels = no_of_labels,\n",
    "                   comment=comment,\n",
    "                   save_dir=save_dir,\n",
    "                   f1_score_mean = f1_score_mean\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4020e520-309c-4846-90fd-b0d6cb542523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba62440d-c50d-4774-9861-3a5d7c6b16c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_kostas_env",
   "language": "python",
   "name": "new_kostas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
